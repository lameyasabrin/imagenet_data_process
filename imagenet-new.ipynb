{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":2801324,"sourceType":"datasetVersion","datasetId":1683795},{"sourceId":2834413,"sourceType":"datasetVersion","datasetId":1733978},{"sourceId":7061095,"sourceType":"datasetVersion","datasetId":4065038},{"sourceId":7067272,"sourceType":"datasetVersion","datasetId":4069528},{"sourceId":7074078,"sourceType":"datasetVersion","datasetId":4074322},{"sourceId":7491226,"sourceType":"datasetVersion","datasetId":4361567},{"sourceId":7496230,"sourceType":"datasetVersion","datasetId":4364861},{"sourceId":7500604,"sourceType":"datasetVersion","datasetId":4367707},{"sourceId":7597474,"sourceType":"datasetVersion","datasetId":4422428},{"sourceId":7600082,"sourceType":"datasetVersion","datasetId":4424192},{"sourceId":7605927,"sourceType":"datasetVersion","datasetId":4428261},{"sourceId":7609156,"sourceType":"datasetVersion","datasetId":4430523},{"sourceId":7683945,"sourceType":"datasetVersion","datasetId":4483418},{"sourceId":7689660,"sourceType":"datasetVersion","datasetId":4487477},{"sourceId":7693498,"sourceType":"datasetVersion","datasetId":4490147},{"sourceId":7698776,"sourceType":"datasetVersion","datasetId":4493768},{"sourceId":7899291,"sourceType":"datasetVersion","datasetId":4638979},{"sourceId":7907914,"sourceType":"datasetVersion","datasetId":4645342},{"sourceId":7912174,"sourceType":"datasetVersion","datasetId":4648389},{"sourceId":8018787,"sourceType":"datasetVersion","datasetId":4724815},{"sourceId":8032276,"sourceType":"datasetVersion","datasetId":4734565},{"sourceId":8070927,"sourceType":"datasetVersion","datasetId":4762235},{"sourceId":8077506,"sourceType":"datasetVersion","datasetId":4767114},{"sourceId":8082215,"sourceType":"datasetVersion","datasetId":4770501},{"sourceId":8168630,"sourceType":"datasetVersion","datasetId":4833985},{"sourceId":8177653,"sourceType":"datasetVersion","datasetId":4840828},{"sourceId":8187730,"sourceType":"datasetVersion","datasetId":4848368},{"sourceId":8208824,"sourceType":"datasetVersion","datasetId":4864378},{"sourceId":10051476,"sourceType":"datasetVersion","datasetId":6193172}],"dockerImageVersionId":30589,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!apt-get update && apt-get install -y python3-opencv\n!pip install tensorflow==2.12.0\n# !pip install keras-cv tensorflow --upgrade\n!pip install opencv-python\n!pip install scikit-learn\n!pip install matplotlib\n# !pip install albumentations==1.3.0\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import axes_grid1\nfrom IPython.display import clear_output\n# import keras_cv\nimport warnings\nwarnings.simplefilter('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\n# import keras_cv\nimport tensorflow as tf\nfrom tensorflow import keras\nimport albumentations as A\nclear_output()\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2024-01-26T14:46:25.093514Z","iopub.execute_input":"2024-01-26T14:46:25.094341Z","iopub.status.idle":"2024-01-26T14:46:29.396248Z","shell.execute_reply.started":"2024-01-26T14:46:25.094299Z","shell.execute_reply":"2024-01-26T14:46:29.395231Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T14:46:29.398301Z","iopub.execute_input":"2024-01-26T14:46:29.398967Z","iopub.status.idle":"2024-01-26T14:46:29.406886Z","shell.execute_reply.started":"2024-01-26T14:46:29.398930Z","shell.execute_reply":"2024-01-26T14:46:29.405762Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ROOT_DIR_PART_0 = \"/kaggle/input/imagenet-1k-tfrecords-ilsvrc2012-part-0\"\nROOT_DIR_PART_1 = \"/kaggle/input/imagenet-1k-tfrecords-ilsvrc2012-part-1\"\ntrain_shard_suffix = 'train-*-of-01024'\nval_shard_suffix   = 'validation-*-of-00128'\n\ntrain_set_path = sorted(\n    tf.io.gfile.glob(ROOT_DIR_PART_0 + f'/train/{train_shard_suffix}') +\n    tf.io.gfile.glob(ROOT_DIR_PART_1 + f'/train/{train_shard_suffix}')\n)\nval_set_path = sorted(\n    tf.io.gfile.glob(ROOT_DIR_PART_0 + f'/validation/{val_shard_suffix}')\n)\n\nlen(train_set_path), len(val_set_path)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T14:46:29.408188Z","iopub.execute_input":"2024-01-26T14:46:29.408566Z","iopub.status.idle":"2024-01-26T14:46:29.575070Z","shell.execute_reply.started":"2024-01-26T14:46:29.408529Z","shell.execute_reply":"2024-01-26T14:46:29.574064Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 16 * strategy.num_replicas_in_sync\nimage_shape = (224, 224)\nIMAGE_SIZE = [224,224]\ntrain_set_len = 626000 + 655167  # 626000 for part 655167 or part 1: 655167\nvalid_set_len = 50000\ntrain_step = train_set_len // batch_size\nval_step = valid_set_len // batch_size\nAUTO  = tf.data.AUTOTUNE\nTRAINING_FILENAMES = train_set_path\nTEST_FILENAMES =  val_set_path\nAUG_BATCH =batch_size\nBATCH_SIZE =batch_size","metadata":{"execution":{"iopub.status.busy":"2024-01-26T14:46:29.577475Z","iopub.execute_input":"2024-01-26T14:46:29.577765Z","iopub.status.idle":"2024-01-26T14:46:29.584300Z","shell.execute_reply.started":"2024-01-26T14:46:29.577741Z","shell.execute_reply":"2024-01-26T14:46:29.583380Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def deserialization_fn(serialized_example):\n#     parsed_example = tf.io.parse_single_example(\n#         serialized_example,\n#         features={\n#             'image/encoded': tf.io.FixedLenFeature([], tf.string),\n#             'image/class/label': tf.io.FixedLenFeature([], tf.int64),\n#         }\n#     )\n#     image = tf.image.decode_jpeg(parsed_example['image/encoded'], channels=3)\n#     image = tf.image.resize(image, image_shape,method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n#     label = tf.cast(parsed_example['image/class/label'], tf.int64) - 1  # [0-999]\n#     return image, label","metadata":{"execution":{"iopub.status.busy":"2024-01-26T14:46:29.585256Z","iopub.execute_input":"2024-01-26T14:46:29.585557Z","iopub.status.idle":"2024-01-26T14:46:29.592837Z","shell.execute_reply.started":"2024-01-26T14:46:29.585510Z","shell.execute_reply":"2024-01-26T14:46:29.592000Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cutmix(image, label, PROBABILITY = 1.0):\n   \n    DIM = IMAGE_SIZE[0]\n    CLASSES = 1000\n    \n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        b = tf.random.uniform([],0,1) \n        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH//2)\n        yb = tf.math.minimum(DIM,y+WIDTH//2)\n        xa = tf.math.maximum(0,x-WIDTH//2)\n        xb = tf.math.minimum(DIM,x+WIDTH//2)\n        one = image[j,ya:yb,0:xa,:]\n        two = image[k,ya:yb,xa:xb,:]\n        three = image[j,ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n        imgs.append(img)\n        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n        if len(label.shape)==1:\n            lab1 = tf.one_hot(label[j],CLASSES)\n            lab2 = tf.one_hot(label[k],CLASSES)\n        else:\n            lab1 = label[j,]\n            lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n    return image2,label2","metadata":{"execution":{"iopub.status.busy":"2024-01-26T14:46:29.594137Z","iopub.execute_input":"2024-01-26T14:46:29.594582Z","iopub.status.idle":"2024-01-26T14:46:29.608646Z","shell.execute_reply.started":"2024-01-26T14:46:29.594549Z","shell.execute_reply":"2024-01-26T14:46:29.607815Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mixup(image, label, PROBABILITY = .5):\n\n    DIM = IMAGE_SIZE[0]\n    CLASSES = 1000\n    \n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n        img1 = image[j,]\n        img2 = image[k,]\n        imgs.append((1-a)*img1 + a*img2)\n        if len(label.shape)==1:\n            lab1 = tf.one_hot(label[j],CLASSES)\n            lab2 = tf.one_hot(label[k],CLASSES)\n        else:\n            lab1 = label[j,]\n            lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n    return image2,label2","metadata":{"execution":{"iopub.status.busy":"2024-01-26T14:46:29.609898Z","iopub.execute_input":"2024-01-26T14:46:29.610228Z","iopub.status.idle":"2024-01-26T14:46:29.622593Z","shell.execute_reply.started":"2024-01-26T14:46:29.610198Z","shell.execute_reply":"2024-01-26T14:46:29.621781Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def transform(image,label):\n    DIM = IMAGE_SIZE[0]\n    CLASSES = 1000\n    SWITCH = 0.5\n    CUTMIX_PROB = 0.666\n    MIXUP_PROB = 0.666\n    image2, label2 = cutmix(image, label, CUTMIX_PROB)\n    image3, label3 = mixup(image, label, MIXUP_PROB)\n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n        imgs.append(P*image2[j,]+(1-P)*image3[j,])\n        labs.append(P*label2[j,]+(1-P)*label3[j,])\n    image4 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label4 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n    return image4,label4","metadata":{"execution":{"iopub.status.busy":"2024-01-26T14:46:29.623742Z","iopub.execute_input":"2024-01-26T14:46:29.624027Z","iopub.status.idle":"2024-01-26T14:46:29.636063Z","shell.execute_reply.started":"2024-01-26T14:46:29.624003Z","shell.execute_reply":"2024-01-26T14:46:29.635148Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n\n\n\nfrom tensorflow.keras.layers.experimental import preprocessing\n\ndef onehot(image,label):\n    CLASSES = 1000\n    return image,tf.one_hot(label,CLASSES)\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.image.resize(image, IMAGE_SIZE,method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        'image/encoded': tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        'image/class/label': tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image/encoded'])\n    label = tf.cast(example['image/class/label'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        'image/class/label': tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image/encoded'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled = True, ordered = False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # Diregarding data order. Order does not matter since we will be shuffling the data anyway\n    \n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # use data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls = AUTO) # returns a dataset of (image, label) pairs if labeled = True or (image, id) pair if labeld = False\n    return dataset\n\n# keras_aug = tf.keras.Sequential([\n#     preprocessing.RandomFlip(\"horizontal\"),\n#     preprocessing.RandomZoom(\n#         height_factor=(-0.05, -0.015),\n#         width_factor=(-0.05, -0.015)), \n#     preprocessing.RandomContrast(.15),\n# #     preprocessing.RandomCrop(120, 120),\n    \n#     preprocessing.RandomRotation(0.1)\n# ])\n\n\n\ndef album_augment(image):\n    transforms = A.Compose([\n        \n         A.OneOf([\n        A.RandomCrop(224, 224),\n        A.HorizontalFlip(),\n        A.SafeRotate(limit=[-60,60]),\n        A.ShiftScaleRotate(p=0.3),\n        A.Affine(),\n        A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n        A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1)),\n        A.ToSepia (always_apply=False),\n        A.RingingOvershoot (blur_limit=(7, 15), cutoff=(0.7853981633974483, 1.5707963267948966), always_apply=False),\n        A.RandomRain(),\n        A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=2.5),\n        A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0, angle_upper=1, num_flare_circles_lower=6,\n                         num_flare_circles_upper=10, src_radius=100, src_color=(255, 255, 255)),     \n        A.Cutout(num_holes=2, max_h_size=50, max_w_size=50),\n        A.Downscale(scale_min=0.85, scale_max=0.85),\n        A.CoarseDropout()],p=.5),\n        \n        \n        A.OneOf([\n#         A.Resize (256, 256, interpolation=1, always_apply=True, p=.5),\n        A.RandomResizedCrop (180, 180, scale=(0.29, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1, always_apply=False, p=1.0),\n        A.CenterCrop(224,224),\n        A.ColorJitter (brightness=0.25, contrast=0.2, saturation=0.4, hue=0.5, always_apply=False, p=0.5),\n        A.RandomCrop(224, 224),\n        A.SafeRotate(limit=[-45,45]),\n       ],p=.5),\n\n        A.Resize (224, 224, interpolation=1, always_apply=True, p=1)])\n\n\n\n    aug_image = transforms(image=image)['image']\n    aug_image = tf.cast(x=aug_image, dtype=tf.float32)\n\n# def album_augment(image):\n#     transforms = A.Compose([\n#              A.OneOf([A.Resize (256, 256, interpolation=1, always_apply=True, p=.5),\n#             A.RandomResizedCrop(224, 224)],p=.5),\n            \n#             A.OneOf([A.HorizontalFlip(),\n# #                     A.VerticalFlip(),\n#                     A.Rotate (limit=[-45,45]),\n# #                     A.Transpose()\n#                     ],p=.5),\n            \n#             A.OneOf([A.ShiftScaleRotate(p=0.3),\n#                     A.Affine()],p=.5),\n        \n#             A.OneOf([A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n#                     A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1)),\n#                     A.ToSepia (always_apply=False),\n#                     ],p=.5),\n        \n#             A.OneOf([\n#                     A.RingingOvershoot (blur_limit=(7, 15), cutoff=(0.7853981633974483, 1.5707963267948966), always_apply=False),\n#                      A.RandomRain(),\n#                      A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=2.5),\n#                      A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0, angle_upper=1, num_flare_circles_lower=6, num_flare_circles_upper=10, src_radius=100, src_color=(255, 255, 255)),\n# #                     A.FancyPCA()\n#                     ],p=.5),\n# #             A.RandomToneCurve (scale=0.1, always_apply=False, p=0.5),\n#             A.OneOf([A.Cutout(num_holes=2, max_h_size=50, max_w_size=50),\n#                     A.Downscale(scale_min=0.85, scale_max=0.85),\n#                     A.CoarseDropout()],p=.5),\n           \n#             A.Resize (224, 224, interpolation=1, always_apply=True, p=1)\n            \n            \n#             ], p=1)\n\n\n\n#     aug_image = transforms(image=image)['image']\n#     aug_image = tf.cast(x=aug_image, dtype=tf.float32)\n   \n    return aug_image    \n\ndef data_augment(image, label):\n    aug_func = tf.numpy_function(func=album_augment, inp=[image], Tout=[tf.float32])\n    return aug_func,label\n\n\ndef get_training_dataset(dataset, do_aug=True):\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.batch(AUG_BATCH)\n    if do_aug: dataset = dataset.map(mixup, num_parallel_calls=AUTO) # note we put AFTER batching\n    dataset = dataset.unbatch()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\n\n\n\ndef get_validation_dataset(dataset, do_onehot=True):\n    dataset = dataset.batch(BATCH_SIZE)\n    if do_onehot: dataset = dataset.map(onehot, num_parallel_calls=AUTO) # we must use one hot like augmented train data\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T15:18:58.081511Z","iopub.execute_input":"2024-01-26T15:18:58.081958Z","iopub.status.idle":"2024-01-26T15:18:58.108879Z","shell.execute_reply.started":"2024-01-26T15:18:58.081926Z","shell.execute_reply":"2024-01-26T15:18:58.107835Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_elements = get_training_dataset(load_dataset(TRAINING_FILENAMES))\n# augmented_element = all_elements.repeat().batch(AUG_BATCH).map(transform)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T15:18:58.397111Z","iopub.execute_input":"2024-01-26T15:18:58.397525Z","iopub.status.idle":"2024-01-26T15:19:02.435124Z","shell.execute_reply.started":"2024-01-26T15:18:58.397492Z","shell.execute_reply":"2024-01-26T15:19:02.434325Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid = get_validation_dataset(load_dataset(TEST_FILENAMES))","metadata":{"execution":{"iopub.status.busy":"2024-01-26T15:19:02.436765Z","iopub.execute_input":"2024-01-26T15:19:02.437054Z","iopub.status.idle":"2024-01-26T15:19:02.480138Z","shell.execute_reply.started":"2024-01-26T15:19:02.437028Z","shell.execute_reply":"2024-01-26T15:19:02.479354Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_elements","metadata":{"execution":{"iopub.status.busy":"2024-01-26T15:19:02.481164Z","iopub.execute_input":"2024-01-26T15:19:02.481492Z","iopub.status.idle":"2024-01-26T15:19:02.487379Z","shell.execute_reply.started":"2024-01-26T15:19:02.481465Z","shell.execute_reply":"2024-01-26T15:19:02.486564Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid","metadata":{"execution":{"iopub.status.busy":"2024-01-26T15:19:02.489774Z","iopub.execute_input":"2024-01-26T15:19:02.490644Z","iopub.status.idle":"2024-01-26T15:19:02.498463Z","shell.execute_reply.started":"2024-01-26T15:19:02.490609Z","shell.execute_reply":"2024-01-26T15:19:02.497582Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nrow = 6; col = 4;\nrow = min(row,AUG_BATCH//col)\n# all_elements = get_training_dataset(load_dataset(TRAINING_FILENAMES)).unbatch()\n# augmented_element = all_elements.repeat().batch(AUG_BATCH).map(transform)\n\nfor (img,label) in all_elements:\n    print()\n    plt.figure(figsize=(15,int(15*row/col)))\n    for j in range(row*col):\n        plt.subplot(row,col,j+1)\n        plt.axis('off')\n        plt.imshow(img[j,])\n    plt.show()\n    break","metadata":{"execution":{"iopub.status.busy":"2024-01-26T15:21:51.129135Z","iopub.execute_input":"2024-01-26T15:21:51.129891Z","iopub.status.idle":"2024-01-26T15:22:11.615155Z","shell.execute_reply.started":"2024-01-26T15:21:51.129858Z","shell.execute_reply":"2024-01-26T15:22:11.614257Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nrow = 6; col = 4;\nrow = min(row,AUG_BATCH//col)\n# all_elements = get_training_dataset(load_dataset(TRAINING_FILENAMES)).unbatch()\n# augmented_element = all_elements.repeat().batch(AUG_BATCH).map(transform)\n\nfor (img,label) in valid:\n    print()\n    plt.figure(figsize=(15,int(15*row/col)))\n    for j in range(row*col):\n        plt.subplot(row,col,j+1)\n        plt.axis('off')\n        plt.imshow(img[j,])\n    plt.show()\n    break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"initial_learning_rate = 0.175\ndecay_factor = 0.99\ndecay_epochs = 12.4  # Number of epochs after which to decay the learning rate\n\n# Create a learning rate schedule using a learning rate scheduler\ndef lr_schedule(epoch):\n    lr = initial_learning_rate * (decay_factor ** (epoch / decay_epochs))\n    return lr\n\n# Create a learning rate scheduler callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nos.mkdir(\"/kaggle/working/imagenet\")\nos.mkdir(\"/kaggle/working/imagenet/chief\")\nfiles = os.listdir(\"/kaggle/input/imagenet-nov30/imagenet/chief/\")\nfor i in files:\n    shutil.copy(\"/kaggle/input/imagenet-nov30/imagenet/chief/\"+i,\"/kaggle/working/imagenet/chief/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pickle \nimport math\nimport cv2 \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import auc\nfrom skimage.transform import resize\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom scipy.ndimage.interpolation import zoom\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.metrics import categorical_accuracy\nfrom tensorflow.keras.optimizers import Adam,SGD,Adamax\n#from keras.models import load_model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Conv2D,Add,Concatenate,MaxPooling2D,Activation,GlobalAveragePooling2D,LocallyConnected2D,SeparableConv2D\nfrom tensorflow.keras.layers import Dropout,Cropping2D, Input,DepthwiseConv2D, AveragePooling2D, Flatten, Dense, Reshape, BatchNormalization,Multiply\nfrom tensorflow.keras.layers import UpSampling2D,ZeroPadding2D,Dot,Lambda\nfrom tensorflow.keras.regularizers import l2,l1\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import RandomFourierFeatures\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nimport albumentations as albu","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nact = \"elu\"\n\ninit = \"he_uniform\"\n# init =  tf.keras.initializers.Ones()\ndef bock_one(input_data,F1,use_bias, activation, drop_out):\n\n    conv1 = Conv2D(F1,(1,1),strides=(1, 1),padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(input_data)\n\n#     conv1 = BatchNormalization()(conv1)\n#     conv1 = Activation(activation)(conv1)\n\n    conv = Conv2D(F1,(1,1),strides=(1, 1),padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(conv1)\n    conv = BatchNormalization()(conv)\n\n#     conv = DepthwiseConv2D((3,3),strides=(1, 1),padding=\"same\",\n#                            use_bias=use_bias,\n#                            kernel_initializer=init)(conv)\n    \n    conv = Add()([conv,conv1])\n    \n    conv2 = Conv2D(F1,(1,1),strides=(1, 1),padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(conv)\n    \n#     conv2 = BatchNormalization()(conv2)\n#     conv2 = Activation(activation)(conv2)\n\n    conv = Conv2D(F1,(1,1),strides=(1, 1),padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(conv2)\n    conv = BatchNormalization()(conv)\n    \n    conv = block_two(conv,use_bias, activation, drop_out)\n    # for  _ in range(3):\n    conv = Conv2D(F1,(1,1),strides=(1, 1),padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(conv)\n\n    conv = BatchNormalization()(conv)\n#     conv = Activation(activation)(conv)\n    # conv = BatchNormalization()(conv)\n    conv = Conv2D(F1,(1,1),strides=(1, 1),padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(conv)\n    conv = BatchNormalization()(conv)\n    conv = Add()([conv,conv2])\n    conv = Activation(activation)(conv)\n    \n    \n\n    conv4 = Conv2D(F1,(1,1),strides=(1, 1),padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(conv)\n    \n#     conv4 = BatchNormalization()(conv4)\n#     conv4 = Activation(activation)(conv4)\n\n\n    conv = Conv2D(F1,(1,1),strides=(1, 1),padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(conv4)\n    conv = conv = BatchNormalization()(conv)\n    \n    \n#     conv = DepthwiseConv2D((3,3),strides=(1, 1),padding=\"same\",\n#                            use_bias=use_bias,\n#                            kernel_initializer=init)(conv)\n                \n    conv = Add()([conv,conv4])\n#     conv = Conv2D(F1,(1,1),strides=(1, 1),\n#                   padding=\"same\",\n#                   use_bias=use_bias,\n#                   kernel_initializer=\"he_uniform\")(conv)\n    # for _ in range(3):\n    conv = Conv2D(F1,(1,1),strides=(1, 1),\n                  padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(conv)\n    \n#     conv = BatchNormalization()(conv)\n#     conv = Activation(activation)(conv)\n\n    conv = Conv2D(F1,(1,1),strides=(1, 1),padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(conv)\n                  \n#     conv = DepthwiseConv2D((3,3),strides=(1, 1),padding=\"same\",\n#                            use_bias=use_bias,\n#                            kernel_initializer=init)(conv)\n    \n    # kernel_regularizer=l2(0.001)\n    conv = BatchNormalization()(conv)\n    conv = Activation(activation)(conv)\n    conv = Dropout(drop_out)(conv)\n    conv = Add()([input_data,conv])\n    \n    #dot  = Dot(axes=1)([input_data,conv])\n    #reshape = Reshape((28,28,64))(dot)\n    return conv\n\n    \n\n\ndef block_two(input_data,use_bias, activation, drop_out):\n\n    conv = DepthwiseConv2D((5,5),strides=(1, 1),padding=\"same\",\n                           use_bias=use_bias,\n                           kernel_initializer=init)(input_data)\n    \n    \n    conv = BatchNormalization()(conv)\n    conv = Activation(activation)(conv)\n#     conv = Dropout(drop_out)(conv)\n    F1 = conv.shape[3]\n#     conv = ZeroPadding2D((1,1))(conv)\n    conv = Conv2D(F1,(1,1),strides=(1, 1),padding=\"same\",\n                  use_bias=use_bias,\n                  kernel_initializer=init)(conv)\n    \n    conv = DepthwiseConv2D((3,3),strides=(1, 1),padding=\"same\",\n                           use_bias=use_bias,\n                           kernel_initializer=init)(conv)\n\n    conv = BatchNormalization()(conv)\n    conv = Activation(activation)(conv)\n    \n    conv = Dropout(drop_out)(conv)\n    #conv = Add()([input_data,conv])\n    \n    return conv\n\ndef  dense_layer(input_data,x):\n    xx= input_data.shape[1]\n    \n    reshape = Reshape((1,1,int(xx)))(input_data)\n    return reshape\n\ndef conv_layer(input_data, F1):\n    conv = Conv2D(F1,(1,1),strides=(1, 1),\n                  padding=\"same\",\n                  use_bias=False,\n                  kernel_initializer=init)(input_data)\n    conv = BatchNormalization()(conv)\n    \n    return conv\n\n\n\nwith strategy.scope():\n    input_data =Input((224,224,3))\n\n    conv_1 = conv_layer(input_data,256) #64x64\n    conv_2 = bock_one(conv_1,256,False, act, .5)#64x64\n    conv_3 = block_two(conv_2,False, act, .5)#64x64\n    max_1  = AveragePooling2D()(conv_3)#64x64---->>#16x16\n\n    ################################# 16x16\n    conv_5 = bock_one(max_1,256,False, act, .5)#16x16\n    conv_6 = conv_layer(conv_5, 256)#16x16\n\n    add_1  = Add()([max_1,conv_6])#  32X32\n    conv_7 = conv_layer(add_1, 48)\n    conv_77 = bock_one(conv_7,48,False, act, .5)\n    conv_77 = block_two(conv_77,False, act, .5)\n    # max_2  = MaxPooling2D()(conv_7)\n    max_2  = AveragePooling2D()(conv_77)\n    #############################\n    conv_8 = bock_one(max_2,48,False, act, .5)\n    conv_8 = conv_layer(conv_8, 48)\n    global_avg_1 = GlobalAveragePooling2D()(conv_8)\n\n    dense_1 =dense_layer(global_avg_1,128)  #128\n\n    #     global_avg_2 = GlobalAveragePooling2D()(dense_1)\n    #     reshape_1 = Reshape((1,1,448))(global_avg_2)\n\n    conv_9 = Conv2D(24,(1,1),strides=(1, 1),padding=\"same\",\n                      use_bias=False,\n                      kernel_initializer=init)(dense_1)\n    conv_10 = Conv2D(48,(1,1),strides=(1, 1),padding=\"same\",\n                      use_bias=False,\n                      kernel_initializer=init)(conv_9)\n\n    add_2= Add()([conv_77,conv_10])\n\n    '''\n    **************************************************************************\n    '''\n\n\n    conv_11 = conv_layer(add_2,80) #64x64\n    conv_21 = bock_one(conv_11,80,False, act, .5)#64x64\n    conv_31 = block_two(conv_21,False, act, .5)#64x64\n    max_11  = AveragePooling2D()(conv_31)#64x64---->>#16x16\n\n    conv_51 = bock_one(max_11,80,False, act, .5)#16x16\n    conv_61 = conv_layer(conv_51, 80)#16x16\n\n    add_11  = Add()([max_11,conv_61])#  32X32\n    conv_71 = conv_layer(add_11, 112)\n    conv_771 = bock_one(conv_71,112,False, act, .5)\n    conv_771 = block_two(conv_771,False, act, .5)\n    # max_2  = MaxPooling2D()(conv_7)\n    max_21  = AveragePooling2D()(conv_771)\n\n    conv_81 = bock_one(max_21,112,False, act, .5)\n    conv_81 = conv_layer(conv_81, 112)\n    global_avg_11 = GlobalAveragePooling2D()(conv_81)\n\n    dense_11 =dense_layer(global_avg_11,128)  #128\n\n    #     global_avg_2 = GlobalAveragePooling2D()(dense_1)\n    #     reshape_1 = Reshape((1,1,448))(global_avg_2)\n\n    conv_91 = Conv2D(32,(1,1),strides=(1, 1),padding=\"same\",\n                      use_bias=False,\n                      kernel_initializer=init)(dense_11)\n    conv_101 = Conv2D(112,(1,1),strides=(1, 1),padding=\"same\",\n                      use_bias=False,\n                      kernel_initializer=init)(conv_91)\n\n    add_21= Add()([conv_771,conv_101])\n\n\n\n    '''\n    *************************************************************************\n    '''\n\n\n\n    conv_12 = conv_layer(add_21,224) #64x64\n    conv_22 = bock_one(conv_12,224,False, act, .5)#64x64\n    conv_32 = block_two(conv_22,False, act, .5)#64x64\n    max_12  = AveragePooling2D()(conv_32)#64x64---->>#16x16\n\n    conv_52 = bock_one(max_12,224,False, act, .5)#16x16\n    conv_62 = conv_layer(conv_52, 224)#16x16\n\n    add_12  = Add()([max_12,conv_62])#  32X32\n    conv_72 = conv_layer(add_12, 512)\n    conv_772 = bock_one(conv_72,512,False, act, .5)\n    conv_772 = block_two(conv_772,False, act, .5)\n# #     max_2  = MaxPooling2D()(conv_7)\n#     max_22  = AveragePooling2D()(conv_772)\n\n# #     conv_82 = bock_one(max_22,420,False, act, .5)\n# #     conv_82 = conv_layer(conv_82, 420)\n#     global_avg_12 = GlobalAveragePooling2D()(max_22)\n\n#     dense_12 =dense_layer(global_avg_12,224)  #128\n\n#     #     global_avg_2 = GlobalAveragePooling2D()(dense_1)\n#     #     reshape_1 = Reshape((1,1,448))(global_avg_2)\n\n#     conv_92 = Conv2D(224,(1,1),strides=(1, 1),padding=\"same\",\n#                       use_bias=False,\n#                       kernel_initializer=init)(dense_12)\n#     conv_102 = Conv2D(224,(1,1),strides=(1, 1),padding=\"same\",\n#                       use_bias=False,\n#                       kernel_initializer=init)(conv_92)\n\n#     add_22= Add()([conv_772,conv_72])\n\n\n\n#     '''\n#     *************************************************************************\n#     '''\n\n\n\n#     conv_13 = conv_layer(add_22,380) #64x64\n#     conv_23 = bock_one(conv_13,380,False, act, .5)#64x64\n#     conv_33 = block_two(conv_23,False, act, .5)#64x64\n#     max_13  = AveragePooling2D()(conv_33)#64x64---->>#16x16\n\n#     conv_53 = bock_one(max_13,380,False, act, .5)#16x16\n#     conv_63 = conv_layer(conv_53, 380)#16x16\n\n#     add_13  = Add()([max_13,conv_63])#  32X32\n#     conv_73 = conv_layer(add_13, 420)\n#     conv_773 = bock_one(conv_73,420,False, act, .5)\n#     conv_773 = block_two(conv_773,False, act, .5)\n#     # max_2  = MaxPooling2D()(conv_7)\n#     max_23  = AveragePooling2D()(conv_773)\n#     conv_83 = conv_layer(max_23, 480)\n#     conv_83 = bock_one(conv_83,480,False, act, .5)\n#     conv_83 = conv_layer(conv_83, 480)\n   \n\n    conv = GlobalAveragePooling2D()(conv_772)\n    conv = Dropout(.75)(conv)\n    dense = Dense(1000, activation =\"softmax\")(conv)\n                                                      #categorical_crossentropy\n    model = Model(inputs=input_data, outputs=dense)#sparse_categorical_crossentropy,,  Adam(lr=0.0001,decay=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n    model.compile(optimizer=SGD(),#SGD(lr=0.01, decay=1e-5, momentum=0.9, nesterov=True),\n                  loss='categorical_crossentropy',  metrics=[\"accuracy\"])\n    model.summary()\n    \nback_up = tf.keras.callbacks.BackupAndRestore(\n    \"/kaggle/working/imagenet/\", save_freq=\"epoch\", delete_checkpoint=True, save_before_preemption=False\n)\n\nfilename='log.csv'\n\nweight_path=\"{}_res_unet.h5\".format('BEST')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='auto')\n\n\nhistory_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)\n\nhistory = model.fit( all_elements,\n                    validation_data=valid,\n                    steps_per_epoch= 1200000 // batch_size,\n                          epochs=1000,\n                    validation_steps = 25500//batch_size,\n                    callbacks=[checkpoint,lr_callback,back_up,history_logger]\n#                           validation_data=(X_test,Y_test)\n                   )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}